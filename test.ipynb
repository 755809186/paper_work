{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learnning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, matthews_corrcoef, roc_auc_score,\n",
    "                             roc_curve, confusion_matrix, classification_report,recall_score)\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# 计算特异度\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# 计算各项指标并返回结果\n",
    "def evaluate_classifier(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    sn = recall_score(y_test, y_pred)\n",
    "    sp = specificity(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    return sn, sp, acc, mcc, roc_auc\n",
    "# 读取文件内容\n",
    "def read_data(file_path):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            seq, label = line.strip().split()\n",
    "            sequences.append(seq)\n",
    "            labels.append(int(label))\n",
    "    return sequences, labels\n",
    "\n",
    "# 对序列进行编码\n",
    "def encode_sequences(sequences):\n",
    "    unique_chars = sorted(set(''.join(sequences)))\n",
    "    char_to_int = {char: i + 1 for i, char in enumerate(unique_chars)}  # 加1避免与填充值冲突\n",
    "    \n",
    "    encoded_seqs = []\n",
    "    for seq in sequences:\n",
    "        encoded_seq = [char_to_int[char] for char in seq]\n",
    "        encoded_seqs.append(encoded_seq)\n",
    "    \n",
    "\n",
    "    maxlen = max([len(seq) for seq in encoded_seqs])\n",
    "    padded_seqs = pad_sequences(encoded_seqs, maxlen=maxlen, padding='post')\n",
    "    return np.array(padded_seqs)\n",
    "\n",
    "# 准备分类器\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "# 获取文件夹下所有txt文件\n",
    "def get_txt_files(folder_path):\n",
    "    return [file for file in os.listdir(folder_path) if file.endswith('.txt')]\n",
    "\n",
    "# 主要循环\n",
    "folder_path = 'data'\n",
    "txt_files = get_txt_files(folder_path)\n",
    "all_results = []\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    file_path = os.path.join(folder_path, txt_file)\n",
    "    \n",
    "    # 读取和处理数据\n",
    "    sequences, labels = read_data(file_path)\n",
    "    encoded_seqs = encode_sequences(sequences)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(encoded_seqs, labels, test_size=0.2, random_state=42,stratify=labels)\n",
    "\n",
    "    # 对每个数据集计算各分类器结果\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        sn, sp, acc, mcc, roc_auc = evaluate_classifier(clf, X_train, X_test, y_train, y_test)\n",
    "        all_results.append([txt_file, clf_name, sn, sp, acc, mcc, roc_auc])\n",
    "\n",
    "# 创建并显示结果的DataFrame\n",
    "columns = ['Dataset', 'Classifier', 'Sn', 'Sp', 'ACC', 'MCC', 'ROC AUC']\n",
    "all_results_df = pd.DataFrame(all_results, columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "all_results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, matthews_corrcoef, roc_auc_score,\n",
    "                             roc_curve, confusion_matrix, classification_report, recall_score)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense,MaxPooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, MaxPooling1D, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# 获取文件夹下所有txt文件\n",
    "def get_txt_files(folder_path):\n",
    "    return [file for file in os.listdir(folder_path) if file.endswith('.txt')]\n",
    "\n",
    "def read_data(file_path):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            seq, label = line.strip()[:-1], line.strip()[-1]  # 修改此行以适应给定的数据格式\n",
    "            sequences.append(seq)\n",
    "            labels.append(int(label))\n",
    "    return sequences, labels\n",
    "\n",
    "def to_numpy_arrays(X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "# 对序列进行编码并填充长度\n",
    "def encode_and_pad_sequences(sequences, maxlen=None):\n",
    "    unique_chars = sorted(set(''.join(sequences)))\n",
    "    char_to_int = {char: i + 1 for i, char in enumerate(unique_chars)}  # 加1避免与填充值冲突\n",
    "    \n",
    "    encoded_seqs = []\n",
    "    for seq in sequences:\n",
    "        encoded_seq = [char_to_int[char] for char in seq]\n",
    "        encoded_seqs.append(encoded_seq)\n",
    "    \n",
    "    if maxlen is None:\n",
    "        maxlen = max([len(seq) for seq in encoded_seqs])\n",
    "    padded_seqs = pad_sequences(encoded_seqs, maxlen=maxlen, padding='post')\n",
    "    return padded_seqs\n",
    "\n",
    "# 创建CNN模型\n",
    "def create_cnn_model(input_dim, input_length, embedding_dim=5, num_classes=1):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dim, input_length=input_length))\n",
    "    \n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "    # 卷积层\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "\n",
    "    # 最大池化层\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "    # 全局平均池化层\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # 输出层\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# 计算特异度\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# 训练和评估CNN模型\n",
    "def evaluate_cnn_model(X, y, n_splits=5):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    sn_values, sp_values, acc_values, mcc_values, roc_auc_values, fpr_values, tpr_values = [], [], [], [], [], [], []\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  \n",
    "\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        y_prob = model.predict(X_test)[:, 0]\n",
    "        y_pred = np.round(y_prob)\n",
    "\n",
    "        sn = recall_score(y_test, y_pred)\n",
    "        sp = specificity(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "        sn_values.append(sn)\n",
    "        sp_values.append(sp)\n",
    "        acc_values.append(acc)\n",
    "        mcc_values.append(mcc)\n",
    "        roc_auc_values.append(roc_auc)\n",
    "        fpr_values.append(fpr)\n",
    "        tpr_values.append(tpr)\n",
    "\n",
    "    return np.mean(sn_values), np.mean(sp_values), np.mean(acc_values), np.mean(mcc_values), np.mean(roc_auc_values), fpr_values, tpr_values\n",
    "\n",
    "\n",
    "\n",
    "# 获取文件夹下所有txt文件\n",
    "folder_path = 'data'\n",
    "txt_files = get_txt_files(folder_path)\n",
    "all_results = []\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    file_path = os.path.join(folder_path, txt_file)\n",
    "    \n",
    "    # 读取和处理数据\n",
    "    sequences, labels = read_data(file_path)\n",
    "    encoded_seqs = encode_and_pad_sequences(sequences)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(*to_numpy_arrays(encoded_seqs, labels), test_size=0.2, random_state=42,stratify=labels)\n",
    "\n",
    "\n",
    "    # 计算输入维度\n",
    "    unique_chars = sorted(set(''.join(sequences)))\n",
    "    input_dim = len(unique_chars)+1\n",
    "    \n",
    "    # 创建CNN模型\n",
    "    model = create_cnn_model(input_dim=input_dim, input_length=X_train.shape[1], embedding_dim=5, num_classes=1)\n",
    "\n",
    "    # 训练和评估CNN模型\n",
    "    sn, sp, acc, mcc, roc_auc, fpr_values, tpr_values = evaluate_cnn_model(encoded_seqs, np.array(labels))\n",
    "\n",
    "    all_results.append([txt_file, 'CNN', sn, sp, acc, mcc, roc_auc,fpr_values, tpr_values])\n",
    "\n",
    "# 创建并显示结果的DataFrame\n",
    "columns = ['Dataset', 'Classifier', 'Sn', 'Sp', 'ACC', 'MCC', 'ROC AUC','fpr', 'tpr']\n",
    "all_results_df = pd.DataFrame(all_results, columns=columns)\n",
    "print(all_results_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 绘制 AUC 曲线图\n",
    "plt.figure()\n",
    "for index, result in enumerate(all_results):\n",
    "    plt.plot(result[-2], result[-1], label=f\"{result[0]} (AUC = {result[-3]:.2f})\")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-HOT + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, matthews_corrcoef, roc_auc_score,\n",
    "                             roc_curve, confusion_matrix, classification_report, recall_score)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense,MaxPooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, MaxPooling1D, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "# 获取文件夹下所有txt文件\n",
    "def get_txt_files(folder_path):\n",
    "    return [file for file in os.listdir(folder_path) if file.endswith('.txt')]\n",
    "\n",
    "def read_data(file_path):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            seq, label = line.strip()[:-1], line.strip()[-1]  # 修改此行以适应给定的数据格式\n",
    "            sequences.append(seq)\n",
    "            labels.append(int(label))\n",
    "    return sequences, labels\n",
    "\n",
    "def to_numpy_arrays(X, y):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def encode_and_pad_sequences(sequences, maxlen=None, num_classes=None):\n",
    "    unique_chars = sorted(set(''.join(sequences)))\n",
    "    char_to_int = {char: i for i, char in enumerate(unique_chars)}\n",
    "    \n",
    "    encoded_seqs = []\n",
    "    for seq in sequences:\n",
    "        encoded_seq = [char_to_int[char] for char in seq]\n",
    "        encoded_seqs.append(encoded_seq)\n",
    "    \n",
    "    if maxlen is None:\n",
    "        maxlen = max([len(seq) for seq in encoded_seqs])\n",
    "    padded_seqs = pad_sequences(encoded_seqs, maxlen=maxlen, padding='post')\n",
    "    \n",
    "    if num_classes is None:\n",
    "        num_classes = len(unique_chars) + 1  # 加1为填充值预留空间\n",
    "    one_hot_seqs = to_categorical(padded_seqs, num_classes=num_classes)\n",
    "\n",
    "    return one_hot_seqs\n",
    "\n",
    "\n",
    "# 创建CNN模型\n",
    "def create_cnn_model(input_shape, num_classes=1):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "    # 卷积层\n",
    "    model.add(Conv1D(128, 3, activation='relu', padding='same'))\n",
    "\n",
    "    # 最大池化层\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "\n",
    "    # 全局平均池化层\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # 输出层\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# def create_cnn_model(input_shape, num_classes=1):\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "#     # model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "#     # model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
    "\n",
    "#     # 卷积层\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "#     # 最大池化层\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
    "\n",
    "#     # 全局平均池化层\n",
    "#     model.add(GlobalAveragePooling2D())\n",
    "\n",
    "#     # 输出层\n",
    "#     model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "# 计算特异度\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# 训练和评估CNN模型\n",
    "def evaluate_cnn_model(X, y, n_splits=5):\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    sn_values, sp_values, acc_values, mcc_values, roc_auc_values, fpr_values, tpr_values = [], [], [], [], [], [], []\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  \n",
    "\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "        y_prob = model.predict(X_test)[:, 0]\n",
    "        y_pred = np.round(y_prob)\n",
    "\n",
    "        sn = recall_score(y_test, y_pred)\n",
    "        sp = specificity(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        mcc = matthews_corrcoef(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "\n",
    "        sn_values.append(sn)\n",
    "        sp_values.append(sp)\n",
    "        acc_values.append(acc)\n",
    "        mcc_values.append(mcc)\n",
    "        roc_auc_values.append(roc_auc)\n",
    "        fpr_values.append(fpr)\n",
    "        tpr_values.append(tpr)\n",
    "\n",
    "    return np.mean(sn_values), np.mean(sp_values), np.mean(acc_values), np.mean(mcc_values), np.mean(roc_auc_values), fpr_values, tpr_values\n",
    "\n",
    "# 获取文件夹下所有txt文件\n",
    "folder_path = 'data'\n",
    "txt_files = get_txt_files(folder_path)\n",
    "all_results = []\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    file_path = os.path.join(folder_path, txt_file)\n",
    "    \n",
    "    # 读取和处理数据\n",
    "    sequences, labels = read_data(file_path)\n",
    "    encoded_seqs = encode_and_pad_sequences(sequences)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(*to_numpy_arrays(encoded_seqs, labels), test_size=0.2, random_state=42,stratify=labels)\n",
    "\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])  # 形状为(序列长度, 字符数)\n",
    "    model = create_cnn_model(input_shape=input_shape, num_classes=1)\n",
    "\n",
    "\n",
    "    # 训练和评估CNN模型\n",
    "    sn, sp, acc, mcc, roc_auc, fpr_values, tpr_values = evaluate_cnn_model(encoded_seqs, np.array(labels))\n",
    "\n",
    "    all_results.append([txt_file, 'CNN', sn, sp, acc, mcc, roc_auc,fpr_values, tpr_values])\n",
    "\n",
    "# 创建并显示结果的DataFrame\n",
    "columns = ['Dataset', 'Classifier', 'Sn', 'Sp', 'ACC', 'MCC', 'ROC AUC','fpr', 'tpr']\n",
    "all_results_df = pd.DataFrame(all_results, columns=columns)\n",
    "print(all_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m无法启动 Kernel。 \n",
      "\u001b[1;31m无法启动 Jupyter Server，因为在 Python 环境“/Users/zhudan/miniforge3/envs/python38/bin/python3.8”中找不到包“jupyter”和“notebook”。. \n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 创建并显示结果的DataFrame\n",
    "columns = ['Dataset', 'Classifier', 'Sn', 'Sp', 'ACC', 'MCC', 'ROC AUC','fpr', 'tpr']\n",
    "all_results_df = pd.DataFrame(all_results, columns=columns)\n",
    "print(all_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
